{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i just load the dataset and split to test and train. where the x takes the data and y takes the targett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnist = load_digits()\n",
    "X = pd.DataFrame(mnist.data)\n",
    "Y = pd.DataFrame(mnist.target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3116)\n",
    "\n",
    "#print(X.shape)\n",
    "#print(X.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here is the part where i we implment the Kfold validation. First of all i define the n-splits =5 \n",
    "define a logistic regression model with max_iter = 10,000 because the default won't converge. Then i loop\n",
    "every time using the .fit by the train_index and getting the score on the test_index.\n",
    "\n",
    "Finally i print the the score which is = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652777777777778\n",
      "0.9722222222222222\n",
      "0.9616724738675958\n",
      "0.9686411149825784\n",
      "0.9477351916376306\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "LR = LogisticRegression(max_iter=10000)\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    #print(X_train.iloc[train_index])\n",
    "    #print(\"-------------\")\n",
    "    #print(y_train.iloc[train_index])\n",
    "    LR.fit(X_train.iloc[train_index],y_train.iloc[train_index].values.ravel())\n",
    "    #print(LR.predict(X_train.iloc[test_index]))\n",
    "    print(LR.score(X_train.iloc[test_index], y_train.iloc[test_index]))\n",
    "\n",
    "print(LR.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Defining A hyperparamter space for optmization <b> where we put different values for the different paramters a MLP classfier takes that we will preform a search operation to get the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (10,10,)],\n",
    "    'activation': ['tanh', 'relu','logistic'],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.0001, 0.1,0.05],\n",
    "    'learning_rate': ['constant','adaptive']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> MLP CLASSFIER <b> \n",
    "    \n",
    "we define the MLP CLASSFIER, WE use randmoizedSearchCv to preform the search operation, then wa evalute \n",
    "the model with the best paramters and get the score. The best paramters are printed as well as the score which is 0.98 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best paramters for the model is  {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50, 50), 'alpha': 0.1, 'activation': 'relu'}\n",
      "The accuracy on the test data is 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = MLPClassifier(random_state=1, max_iter=5000).fit(X_train, y_train.values.ravel())\n",
    "model = RandomizedSearchCV(model, parameter_space, random_state=3116)\n",
    "#clf.get_params().keys()\n",
    "model.fit(X_train,y_train.values.ravel())\n",
    "print(\"The best paramters for the model is \",model.best_params_)\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"The accuracy on the test data is\", score)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
